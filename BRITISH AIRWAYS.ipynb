{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44481683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b7d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 10\n",
    "page_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06fe809a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n"
     ]
    }
   ],
   "source": [
    "\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5dc9f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified | Absolutely horrible airline....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |  Having experienced delays a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified | Travelled to Heathrow to Kal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  This flight failed at every le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Verified |  Beware of British Airways and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  ✅ Trip Verified | Absolutely horrible airline....\n",
       "1  ✅ Trip Verified |  Having experienced delays a...\n",
       "2  ✅ Trip Verified | Travelled to Heathrow to Kal...\n",
       "3  Not Verified |  This flight failed at every le...\n",
       "4  Not Verified |  Beware of British Airways and ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c64d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified | Absolutely horrible airline....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |  Having experienced delays a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified | Travelled to Heathrow to Kal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  This flight failed at every le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Verified |  Beware of British Airways and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>✅ Trip Verified |  London to Paris. I wish tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>✅ Trip Verified |  Delivering outstanding cust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>✅ Trip Verified | This was a night flight New ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>✅ Trip Verified |  Amman to London. Appalling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>✅ Trip Verified |  Paphos to London Gatwick in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews\n",
       "0    ✅ Trip Verified | Absolutely horrible airline....\n",
       "1    ✅ Trip Verified |  Having experienced delays a...\n",
       "2    ✅ Trip Verified | Travelled to Heathrow to Kal...\n",
       "3    Not Verified |  This flight failed at every le...\n",
       "4    Not Verified |  Beware of British Airways and ...\n",
       "..                                                 ...\n",
       "995  ✅ Trip Verified |  London to Paris. I wish tha...\n",
       "996  ✅ Trip Verified |  Delivering outstanding cust...\n",
       "997  ✅ Trip Verified | This was a night flight New ...\n",
       "998  ✅ Trip Verified |  Amman to London. Appalling ...\n",
       "999  ✅ Trip Verified |  Paphos to London Gatwick in...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"BA_reviews.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06de652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reviews= df.reviews.str.split('|',expand=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e7a2f",
   "metadata": {},
   "source": [
    "# Step 1: Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f683cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c7c6887",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"BA_reviews.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2eff1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  1000 non-null   int64 \n",
      " 1   reviews     1000 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>499.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288.819436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>249.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>499.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>749.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0\n",
       "count  1000.000000\n",
       "mean    499.500000\n",
       "std     288.819436\n",
       "min       0.000000\n",
       "25%     249.750000\n",
       "50%     499.500000\n",
       "75%     749.250000\n",
       "max     999.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c44a13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      ✅ Trip Verified | Absolutely horrible airline....\n",
      "1      ✅ Trip Verified |  Having experienced delays a...\n",
      "2      ✅ Trip Verified | Travelled to Heathrow to Kal...\n",
      "3      Not Verified |  This flight failed at every le...\n",
      "4      Not Verified |  Beware of British Airways and ...\n",
      "                             ...                        \n",
      "995    ✅ Trip Verified |  London to Paris. I wish tha...\n",
      "996    ✅ Trip Verified |  Delivering outstanding cust...\n",
      "997    ✅ Trip Verified | This was a night flight New ...\n",
      "998    ✅ Trip Verified |  Amman to London. Appalling ...\n",
      "999    ✅ Trip Verified |  Paphos to London Gatwick in...\n",
      "Name: reviews, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eebd328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c681ff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                                            reviews\n",
      "0             0  absolutely horrible airline. communication is ...\n",
      "1             1  having experienced delays and cancellations de...\n",
      "2             2  avelled to heathrow to kalamata and return jou...\n",
      "3             3  this flight failed at every level. we were del...\n",
      "4             4  beware of british airways and their marketing ...\n",
      "..          ...                                                ...\n",
      "995         995  london to paris. i wish that they would update...\n",
      "996         996  delivering outstanding customer service onboar...\n",
      "997         997  his was a night flight new york jfk to london,...\n",
      "998         998  amman to london. appalling service both on the...\n",
      "999         999  paphos to london gatwick in club europe. we ha...\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df['reviews'] = df['reviews'].str.strip()\n",
    "df['reviews']=df['reviews'].str.lstrip('✅ Trip Verified |')\n",
    "df['reviews']=df['reviews'].str.lstrip('Not Verified |')\n",
    "df['reviews']= df['reviews'].str.lower()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "663d553b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>absolutely horrible airline. communication is ...</td>\n",
       "      <td>absolutely horrible airline communication is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>having experienced delays and cancellations de...</td>\n",
       "      <td>having experienced delays and cancellations de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>avelled to heathrow to kalamata and return jou...</td>\n",
       "      <td>avelled to heathrow to kalamata and return jou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>this flight failed at every level. we were del...</td>\n",
       "      <td>this flight failed at every level we were dela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>beware of british airways and their marketing ...</td>\n",
       "      <td>beware of british airways and their marketing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews  \\\n",
       "0           0  absolutely horrible airline. communication is ...   \n",
       "1           1  having experienced delays and cancellations de...   \n",
       "2           2  avelled to heathrow to kalamata and return jou...   \n",
       "3           3  this flight failed at every level. we were del...   \n",
       "4           4  beware of british airways and their marketing ...   \n",
       "\n",
       "                                     Cleaned Reviews  \n",
       "0  absolutely horrible airline communication is t...  \n",
       "1  having experienced delays and cancellations de...  \n",
       "2  avelled to heathrow to kalamata and return jou...  \n",
       "3  this flight failed at every level we were dela...  \n",
       "4  beware of british airways and their marketing ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean(text):\n",
    "# Removes all special characters and numericals leaving the alphabets\n",
    "    text = re.sub('[^A-Za-z]+', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "# Cleaning the text in the review column\n",
    "df['Cleaned Reviews'] = df['reviews'].apply(clean)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19675c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SANDHYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SANDHYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SANDHYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "\"\"\"This punkt tokenizer divides a text into a list of sentences by using an unsupervised algorithm to build a model for abbreviation words, \n",
    "collocations, and words that start sentences. \"\"\"\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e057b8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\SANDHYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\SANDHYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>POS tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>absolutely horrible airline. communication is ...</td>\n",
       "      <td>absolutely horrible airline communication is t...</td>\n",
       "      <td>[(absolutely, r), (horrible, a), (airline, n),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>having experienced delays and cancellations de...</td>\n",
       "      <td>having experienced delays and cancellations de...</td>\n",
       "      <td>[(experienced, v), (delays, n), (cancellations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>avelled to heathrow to kalamata and return jou...</td>\n",
       "      <td>avelled to heathrow to kalamata and return jou...</td>\n",
       "      <td>[(avelled, v), (heathrow, v), (kalamata, v), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>this flight failed at every level. we were del...</td>\n",
       "      <td>this flight failed at every level we were dela...</td>\n",
       "      <td>[(flight, n), (failed, v), (every, None), (lev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>beware of british airways and their marketing ...</td>\n",
       "      <td>beware of british airways and their marketing ...</td>\n",
       "      <td>[(beware, n), (british, a), (airways, n), (mar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews  \\\n",
       "0           0  absolutely horrible airline. communication is ...   \n",
       "1           1  having experienced delays and cancellations de...   \n",
       "2           2  avelled to heathrow to kalamata and return jou...   \n",
       "3           3  this flight failed at every level. we were del...   \n",
       "4           4  beware of british airways and their marketing ...   \n",
       "\n",
       "                                     Cleaned Reviews  \\\n",
       "0  absolutely horrible airline communication is t...   \n",
       "1  having experienced delays and cancellations de...   \n",
       "2  avelled to heathrow to kalamata and return jou...   \n",
       "3  this flight failed at every level we were dela...   \n",
       "4  beware of british airways and their marketing ...   \n",
       "\n",
       "                                          POS tagged  \n",
       "0  [(absolutely, r), (horrible, a), (airline, n),...  \n",
       "1  [(experienced, v), (delays, n), (cancellations...  \n",
       "2  [(avelled, v), (heathrow, v), (kalamata, v), (...  \n",
       "3  [(flight, n), (failed, v), (every, None), (lev...  \n",
       "4  [(beware, n), (british, a), (airways, n), (mar...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# POS tagger dictionary\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    #print(tags)\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "          newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "          #print(tag[0])\n",
    "          #print(pos_dict.get(tag[0]))\n",
    "    return newlist \n",
    "\n",
    "df['POS tagged'] = df['Cleaned Reviews'].apply(token_stop_pos)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c36fcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>absolutely horrible airline. communication is ...</td>\n",
       "      <td>absolutely horrible airline communication is t...</td>\n",
       "      <td>[(absolutely, r), (horrible, a), (airline, n),...</td>\n",
       "      <td>absolutely horrible airline communication te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>having experienced delays and cancellations de...</td>\n",
       "      <td>having experienced delays and cancellations de...</td>\n",
       "      <td>[(experienced, v), (delays, n), (cancellations...</td>\n",
       "      <td>experience delay cancellation depart usa eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>avelled to heathrow to kalamata and return jou...</td>\n",
       "      <td>avelled to heathrow to kalamata and return jou...</td>\n",
       "      <td>[(avelled, v), (heathrow, v), (kalamata, v), (...</td>\n",
       "      <td>avelled heathrow kalamata return journey day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>this flight failed at every level. we were del...</td>\n",
       "      <td>this flight failed at every level we were dela...</td>\n",
       "      <td>[(flight, n), (failed, v), (every, None), (lev...</td>\n",
       "      <td>flight fail every level delay arrive destina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>beware of british airways and their marketing ...</td>\n",
       "      <td>beware of british airways and their marketing ...</td>\n",
       "      <td>[(beware, n), (british, a), (airways, n), (mar...</td>\n",
       "      <td>beware british airway marketing make believe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews  \\\n",
       "0           0  absolutely horrible airline. communication is ...   \n",
       "1           1  having experienced delays and cancellations de...   \n",
       "2           2  avelled to heathrow to kalamata and return jou...   \n",
       "3           3  this flight failed at every level. we were del...   \n",
       "4           4  beware of british airways and their marketing ...   \n",
       "\n",
       "                                     Cleaned Reviews  \\\n",
       "0  absolutely horrible airline communication is t...   \n",
       "1  having experienced delays and cancellations de...   \n",
       "2  avelled to heathrow to kalamata and return jou...   \n",
       "3  this flight failed at every level we were dela...   \n",
       "4  beware of british airways and their marketing ...   \n",
       "\n",
       "                                          POS tagged  \\\n",
       "0  [(absolutely, r), (horrible, a), (airline, n),...   \n",
       "1  [(experienced, v), (delays, n), (cancellations...   \n",
       "2  [(avelled, v), (heathrow, v), (kalamata, v), (...   \n",
       "3  [(flight, n), (failed, v), (every, None), (lev...   \n",
       "4  [(beware, n), (british, a), (airways, n), (mar...   \n",
       "\n",
       "                                               Lemma  \n",
       "0    absolutely horrible airline communication te...  \n",
       "1    experience delay cancellation depart usa eur...  \n",
       "2    avelled heathrow kalamata return journey day...  \n",
       "3    flight fail every level delay arrive destina...  \n",
       "4    beware british airway marketing make believe...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "     if not pos:\n",
    "        lemma = word\n",
    "        lemma_rew = lemma_rew + \" \" + lemma\n",
    "     else:\n",
    "        lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "        lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "df['Lemma'] = df['POS tagged'].apply(lemmatize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17e0b455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>absolutely horrible airline. communication is ...</td>\n",
       "      <td>absolutely horrible airline communication is t...</td>\n",
       "      <td>[(absolutely, r), (horrible, a), (airline, n),...</td>\n",
       "      <td>absolutely horrible airline communication te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>having experienced delays and cancellations de...</td>\n",
       "      <td>having experienced delays and cancellations de...</td>\n",
       "      <td>[(experienced, v), (delays, n), (cancellations...</td>\n",
       "      <td>experience delay cancellation depart usa eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>avelled to heathrow to kalamata and return jou...</td>\n",
       "      <td>avelled to heathrow to kalamata and return jou...</td>\n",
       "      <td>[(avelled, v), (heathrow, v), (kalamata, v), (...</td>\n",
       "      <td>avelled heathrow kalamata return journey day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>this flight failed at every level. we were del...</td>\n",
       "      <td>this flight failed at every level we were dela...</td>\n",
       "      <td>[(flight, n), (failed, v), (every, None), (lev...</td>\n",
       "      <td>flight fail every level delay arrive destina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>beware of british airways and their marketing ...</td>\n",
       "      <td>beware of british airways and their marketing ...</td>\n",
       "      <td>[(beware, n), (british, a), (airways, n), (mar...</td>\n",
       "      <td>beware british airway marketing make believe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews  \\\n",
       "0           0  absolutely horrible airline. communication is ...   \n",
       "1           1  having experienced delays and cancellations de...   \n",
       "2           2  avelled to heathrow to kalamata and return jou...   \n",
       "3           3  this flight failed at every level. we were del...   \n",
       "4           4  beware of british airways and their marketing ...   \n",
       "\n",
       "                                     Cleaned Reviews  \\\n",
       "0  absolutely horrible airline communication is t...   \n",
       "1  having experienced delays and cancellations de...   \n",
       "2  avelled to heathrow to kalamata and return jou...   \n",
       "3  this flight failed at every level we were dela...   \n",
       "4  beware of british airways and their marketing ...   \n",
       "\n",
       "                                          POS tagged  \\\n",
       "0  [(absolutely, r), (horrible, a), (airline, n),...   \n",
       "1  [(experienced, v), (delays, n), (cancellations...   \n",
       "2  [(avelled, v), (heathrow, v), (kalamata, v), (...   \n",
       "3  [(flight, n), (failed, v), (every, None), (lev...   \n",
       "4  [(beware, n), (british, a), (airways, n), (mar...   \n",
       "\n",
       "                                               Lemma  \n",
       "0    absolutely horrible airline communication te...  \n",
       "1    experience delay cancellation depart usa eur...  \n",
       "2    avelled heathrow kalamata return journey day...  \n",
       "3    flight fail every level delay arrive destina...  \n",
       "4    beware british airway marketing make believe...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "010d0310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [(absolutely, r), (horrible, a), (airline, n),...\n",
       "1      [(experienced, v), (delays, n), (cancellations...\n",
       "2      [(avelled, v), (heathrow, v), (kalamata, v), (...\n",
       "3      [(flight, n), (failed, v), (every, None), (lev...\n",
       "4      [(beware, n), (british, a), (airways, n), (mar...\n",
       "                             ...                        \n",
       "995    [(london, n), (paris, v), (wish, v), (would, N...\n",
       "996    [(delivering, v), (outstanding, a), (customer,...\n",
       "997    [(night, n), (flight, n), (new, a), (york, n),...\n",
       "998    [(amman, n), (london, v), (appalling, a), (ser...\n",
       "999    [(paphos, n), (london, v), (gatwick, n), (club...\n",
       "Name: POS tagged, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"POS tagged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e91e6991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absolutely horrible airline. communication is ...</td>\n",
       "      <td>absolutely horrible airline communication te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>having experienced delays and cancellations de...</td>\n",
       "      <td>experience delay cancellation depart usa eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avelled to heathrow to kalamata and return jou...</td>\n",
       "      <td>avelled heathrow kalamata return journey day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this flight failed at every level. we were del...</td>\n",
       "      <td>flight fail every level delay arrive destina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beware of british airways and their marketing ...</td>\n",
       "      <td>beware british airway marketing make believe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>london to paris. i wish that they would update...</td>\n",
       "      <td>london paris wish would update aircraft perh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>delivering outstanding customer service onboar...</td>\n",
       "      <td>deliver outstanding customer service onboard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>his was a night flight new york jfk to london,...</td>\n",
       "      <td>night flight new york jfk london difficult a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>amman to london. appalling service both on the...</td>\n",
       "      <td>amman london appalling service flight subseq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>paphos to london gatwick in club europe. we ha...</td>\n",
       "      <td>paphos london gatwick club europe check leav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews  \\\n",
       "0    absolutely horrible airline. communication is ...   \n",
       "1    having experienced delays and cancellations de...   \n",
       "2    avelled to heathrow to kalamata and return jou...   \n",
       "3    this flight failed at every level. we were del...   \n",
       "4    beware of british airways and their marketing ...   \n",
       "..                                                 ...   \n",
       "995  london to paris. i wish that they would update...   \n",
       "996  delivering outstanding customer service onboar...   \n",
       "997  his was a night flight new york jfk to london,...   \n",
       "998  amman to london. appalling service both on the...   \n",
       "999  paphos to london gatwick in club europe. we ha...   \n",
       "\n",
       "                                                 Lemma  \n",
       "0      absolutely horrible airline communication te...  \n",
       "1      experience delay cancellation depart usa eur...  \n",
       "2      avelled heathrow kalamata return journey day...  \n",
       "3      flight fail every level delay arrive destina...  \n",
       "4      beware british airway marketing make believe...  \n",
       "..                                                 ...  \n",
       "995    london paris wish would update aircraft perh...  \n",
       "996    deliver outstanding customer service onboard...  \n",
       "997    night flight new york jfk london difficult a...  \n",
       "998    amman london appalling service flight subseq...  \n",
       "999    paphos london gatwick club europe check leav...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['reviews','Lemma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "df1['reviews'] = df1['reviews'].str.replace('[^\\w\\s]','')\n",
    "print(df1['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4909b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (4.0.0)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00e94126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (1.9.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from wordcloud) (3.1.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from wordcloud) (8.2.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from wordcloud) (1.22.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sandhya\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud) (52.0.0.post20210125)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f58de1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SANDHYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from string import digits\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import seaborn as sns\n",
    "import re\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b46a23",
   "metadata": {},
   "source": [
    "# Calculate polarity to gather sentiment tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dde9f0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                                            reviews  \\\n",
      "0             0  b   l   u   e   l       h   r   r   b   l   e ...   \n",
      "1             1  h   v   n   g       e   x   p   e   r   e   n ...   \n",
      "2             2  v   e   l   l   e           h   e   h   r   w ...   \n",
      "3             3  h       f   l   g   h       f   l   e         ...   \n",
      "4             4  b   e   w   r   e       f       b   r   h     ...   \n",
      "..          ...                                                ...   \n",
      "995         995  l   n   n           p   r   .           w   h ...   \n",
      "996         996  e   l   v   e   r   n   g       u   n   n   g ...   \n",
      "997         997  h       w           n   g   h       f   l   g ...   \n",
      "998         998  n           l   n   n   .       p   p   l   l ...   \n",
      "999         999  p   p   h           l   n   n       g   w   c ...   \n",
      "\n",
      "                                       Cleaned Reviews  \\\n",
      "0    absolutely horrible airline communication is t...   \n",
      "1    having experienced delays and cancellations de...   \n",
      "2    avelled to heathrow to kalamata and return jou...   \n",
      "3    this flight failed at every level we were dela...   \n",
      "4    beware of british airways and their marketing ...   \n",
      "..                                                 ...   \n",
      "995  london to paris i wish that they would update ...   \n",
      "996  delivering outstanding customer service onboar...   \n",
      "997  his was a night flight new york jfk to london ...   \n",
      "998  amman to london appalling service both on the ...   \n",
      "999  paphos to london gatwick in club europe we had...   \n",
      "\n",
      "                                            POS tagged  \\\n",
      "0    [(absolutely, r), (horrible, a), (airline, n),...   \n",
      "1    [(experienced, v), (delays, n), (cancellations...   \n",
      "2    [(avelled, v), (heathrow, v), (kalamata, v), (...   \n",
      "3    [(flight, n), (failed, v), (every, None), (lev...   \n",
      "4    [(beware, n), (british, a), (airways, n), (mar...   \n",
      "..                                                 ...   \n",
      "995  [(london, n), (paris, v), (wish, v), (would, N...   \n",
      "996  [(delivering, v), (outstanding, a), (customer,...   \n",
      "997  [(night, n), (flight, n), (new, a), (york, n),...   \n",
      "998  [(amman, n), (london, v), (appalling, a), (ser...   \n",
      "999  [(paphos, n), (london, v), (gatwick, n), (club...   \n",
      "\n",
      "                                                 Lemma  polarity      tag  \n",
      "0      absolutely horrible airline communication te...       0.0  Neutral  \n",
      "1      experience delay cancellation depart usa eur...       0.0  Neutral  \n",
      "2      avelled heathrow kalamata return journey day...       0.0  Neutral  \n",
      "3      flight fail every level delay arrive destina...       0.0  Neutral  \n",
      "4      beware british airway marketing make believe...       0.0  Neutral  \n",
      "..                                                 ...       ...      ...  \n",
      "995    london paris wish would update aircraft perh...       0.0  Neutral  \n",
      "996    deliver outstanding customer service onboard...       0.0  Neutral  \n",
      "997    night flight new york jfk london difficult a...       0.0  Neutral  \n",
      "998    amman london appalling service flight subseq...       0.0  Neutral  \n",
      "999    paphos london gatwick club europe check leav...       0.0  Neutral  \n",
      "\n",
      "[1000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "def polarity_calc(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    except:\n",
    "        return None\n",
    "def tag_cal(num):\n",
    "    if num<0:\n",
    "        return 'Negative'\n",
    "    elif num>0:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "        \n",
    "    \n",
    "df['polarity'] = df['reviews'].apply(polarity_calc)\n",
    "\n",
    "\n",
    "df['tag'] = df['polarity'].apply(tag_cal)\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08c55569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "106f0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9855cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tag</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b   l   u   e   l       h   r   r   b   l   e ...</td>\n",
       "      <td>absolutely horrible airline communication is t...</td>\n",
       "      <td>[(absolutely, r), (horrible, a), (airline, n),...</td>\n",
       "      <td>absolutely horrible airline communication te...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>-0.9117</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>h   v   n   g       e   x   p   e   r   e   n ...</td>\n",
       "      <td>having experienced delays and cancellations de...</td>\n",
       "      <td>[(experienced, v), (delays, n), (cancellations...</td>\n",
       "      <td>experience delay cancellation depart usa eur...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>v   e   l   l   e           h   e   h   r   w ...</td>\n",
       "      <td>avelled to heathrow to kalamata and return jou...</td>\n",
       "      <td>[(avelled, v), (heathrow, v), (kalamata, v), (...</td>\n",
       "      <td>avelled heathrow kalamata return journey day...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>h       f   l   g   h       f   l   e         ...</td>\n",
       "      <td>this flight failed at every level we were dela...</td>\n",
       "      <td>[(flight, n), (failed, v), (every, None), (lev...</td>\n",
       "      <td>flight fail every level delay arrive destina...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.8130</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b   e   w   r   e       f       b   r   h     ...</td>\n",
       "      <td>beware of british airways and their marketing ...</td>\n",
       "      <td>[(beware, n), (british, a), (airways, n), (mar...</td>\n",
       "      <td>beware british airway marketing make believe...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.2491</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews  \\\n",
       "0           0  b   l   u   e   l       h   r   r   b   l   e ...   \n",
       "1           1  h   v   n   g       e   x   p   e   r   e   n ...   \n",
       "2           2  v   e   l   l   e           h   e   h   r   w ...   \n",
       "3           3  h       f   l   g   h       f   l   e         ...   \n",
       "4           4  b   e   w   r   e       f       b   r   h     ...   \n",
       "\n",
       "                                     Cleaned Reviews  \\\n",
       "0  absolutely horrible airline communication is t...   \n",
       "1  having experienced delays and cancellations de...   \n",
       "2  avelled to heathrow to kalamata and return jou...   \n",
       "3  this flight failed at every level we were dela...   \n",
       "4  beware of british airways and their marketing ...   \n",
       "\n",
       "                                          POS tagged  \\\n",
       "0  [(absolutely, r), (horrible, a), (airline, n),...   \n",
       "1  [(experienced, v), (delays, n), (cancellations...   \n",
       "2  [(avelled, v), (heathrow, v), (kalamata, v), (...   \n",
       "3  [(flight, n), (failed, v), (every, None), (lev...   \n",
       "4  [(beware, n), (british, a), (airways, n), (mar...   \n",
       "\n",
       "                                               Lemma  polarity      tag  \\\n",
       "0    absolutely horrible airline communication te...       0.0  Neutral   \n",
       "1    experience delay cancellation depart usa eur...       0.0  Neutral   \n",
       "2    avelled heathrow kalamata return journey day...       0.0  Neutral   \n",
       "3    flight fail every level delay arrive destina...       0.0  Neutral   \n",
       "4    beware british airway marketing make believe...       0.0  Neutral   \n",
       "\n",
       "   Sentiment  Analysis  \n",
       "0    -0.9117  Negative  \n",
       "1    -0.2732  Negative  \n",
       "2     0.8578  Positive  \n",
       "3     0.8130  Positive  \n",
       "4     0.2491   Neutral  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# function to calculate vader sentiment\n",
    "def vadersentimentanalysis(review):\n",
    "    vs = analyzer.polarity_scores(review)\n",
    "    return vs['compound']\n",
    "\n",
    "df['Sentiment'] = df['Lemma'].apply(vadersentimentanalysis)\n",
    "\n",
    "# function to analyse\n",
    "def vader_analysis(compound):\n",
    "    if compound >= 0.5:\n",
    "        return 'Positive'\n",
    "    elif compound < 0 :\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "df['Analysis'] = df['Sentiment'].apply(vader_analysis)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd99abb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    503\n",
       "Negative    385\n",
       "Neutral     112\n",
       "Name: Analysis, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_counts = df['Analysis'].value_counts()\n",
    "vader_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5fea87",
   "metadata": {},
   "source": [
    "# Visual Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fee8c68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.patches.Wedge at 0x28746957c40>,\n",
       "  <matplotlib.patches.Wedge at 0x28746acb430>,\n",
       "  <matplotlib.patches.Wedge at 0x28746acba30>],\n",
       " [Text(-0.010367174777798825, 1.0999511451365132, 'Positive'),\n",
       "  Text(-0.3693583227850683, -1.0361343684046975, 'Negative'),\n",
       "  Text(1.2672907463411172, -0.46526784139694655, 'Neutral')],\n",
       " [Text(-0.005654822606072086, 0.5999733518926434, '50.3%'),\n",
       "  Text(-0.2014681760645827, -0.5651642009480168, '38.5%'),\n",
       "  Text(0.7979238032518144, -0.2929464186573367, '11.2%')])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Reviews Analysis\")\n",
    "plt.pie(vader_counts.values, labels = vader_counts.index, explode = (0, 0, 0.25), autopct='%1.1f%%', shadow=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e34e802",
   "metadata": {},
   "source": [
    "# Wordcloud\n",
    "Word Cloud or Tag Clouds is a visualization technique for texts that are natively used for visualizing the tags or keywords from the websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25efa0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a1574bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransposedFont' object has no attribute 'getbbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-9782ba304d5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mshow_wordcloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLemma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-9782ba304d5a>\u001b[0m in \u001b[0;36mshow_wordcloud\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      8\u001b[0m         random_state=1)\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mwordcloud\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwordcloud\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \"\"\"\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    619\u001b[0m         \"\"\"\n\u001b[0;32m    620\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    506\u001b[0m                     font, orientation=orientation)\n\u001b[0;32m    507\u001b[0m                 \u001b[1;31m# get size of resulting text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m                 \u001b[0mbox_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtextbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransposed_font\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"lt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m                 \u001b[1;31m# find possible places using integral image:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                 result = occupancy.sample_position(box_size[3] + self.margin,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\ImageDraw.py\u001b[0m in \u001b[0;36mtextbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"RGBA\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0membedded_color\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m         bbox = font.getbbox(\n\u001b[0m\u001b[0;32m    658\u001b[0m             \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstroke_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TransposedFont' object has no attribute 'getbbox'"
     ]
    }
   ],
   "source": [
    "def show_wordcloud(data):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=100,\n",
    "        max_font_size=30,\n",
    "        scale=3,\n",
    "        random_state=1)\n",
    "\n",
    "    wordcloud=wordcloud.generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "\n",
    "show_wordcloud(df.Lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "917e024a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransposedFont' object has no attribute 'getbbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-32934abe717c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviews'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mwordcloud_positive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \"\"\"\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    619\u001b[0m         \"\"\"\n\u001b[0;32m    620\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[0mfont_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m                 self.generate_from_frequencies(dict(frequencies[:2]),\n\u001b[0m\u001b[0;32m    454\u001b[0m                                                max_font_size=self.height)\n\u001b[0;32m    455\u001b[0m                 \u001b[1;31m# find font sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    506\u001b[0m                     font, orientation=orientation)\n\u001b[0;32m    507\u001b[0m                 \u001b[1;31m# get size of resulting text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m                 \u001b[0mbox_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtextbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransposed_font\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"lt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m                 \u001b[1;31m# find possible places using integral image:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                 result = occupancy.sample_position(box_size[3] + self.margin,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\ImageDraw.py\u001b[0m in \u001b[0;36mtextbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"RGBA\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0membedded_color\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m         bbox = font.getbbox(\n\u001b[0m\u001b[0;32m    658\u001b[0m             \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstroke_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TransposedFont' object has no attribute 'getbbox'"
     ]
    }
   ],
   "source": [
    "text = \" \"\n",
    "for ind in df.index:\n",
    "    if df['tag'][ind] == \"Positive\":\n",
    "        text = text + df['reviews'][ind]\n",
    "      \n",
    "wordcloud_positive = WordCloud().generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbb0983c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-7d32772c94c6>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-49-7d32772c94c6>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    )\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "  def getbbox(\n",
    "    self,\n",
    "    text,\n",
    "    mode=\"\",\n",
    "    direction=None,\n",
    "    features=None,\n",
    "    language=None,\n",
    "    stroke_width=0,\n",
    "    anchor=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d5efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransposedFont:\n",
    "    def __init__(self, font, orientation=None):\n",
    "        \"\"\"\n",
    "  677         Wrapper that creates a transposed font from any existing fo       object.\n",
    "  679 \n",
    "  680         :param font: A font object.\n",
    "  681         :param orientation: An optional orientation.  If given, this should\n",
    "  682             be one of Image.Transpose.FLIP_LEFT_RIGHT, Image.Transpose.FLIP_TOP_BOTTOM,\n",
    "  683             Image.Transpose.ROTATE_90, Image.Transpose.ROTATE_180, or\n",
    "  684             Image.Transpose.ROTATE_270.\n",
    "  685         \"\"\"\n",
    "  686         self.font = font\n",
    "  687         self.orientation = orientation  # any 'transpose' argument, or None\n",
    "  688 \n",
    "  689     def getmask(self, text, mode=\"\", *args, **kwargs):\n",
    "  690         im = self.font.getmask(text, mode, *args, **kwargs)\n",
    "  691         if self.orientation is not None:\n",
    "  692             return im.transpose(self.orientation)\n",
    "  693         return im\n",
    "  694 \n",
    "  695     def getbbox(self, text, *args, **kwargs):\n",
    "  696         # TransposedFont doesn't support getmask2, move top-left point to (0, 0)\n",
    "  697         # this has no effect on ImageFont and simulates anchor=\"lt\" for FreeTypeFont\n",
    "  698         left, top, right, bottom = self.font.getbbox(text, *args, **kwargs)\n",
    "  699         width = right - left\n",
    "  700         height = bottom - top\n",
    "  701         if self.orientation in (Image.Transpose.ROTATE_90, Image.Transpose.ROTATE_270):\n",
    "  702             return 0, 0, height, width\n",
    "  703         return 0, 0, width, height"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
